---
title: "The spectral Galerkin method and Shenfun programming"
subtitle: "11 June 2024, Athens Greece"
author: "Prof. Mikael Mortensen, University of Oslo"
format:
  revealjs: 
    theme: [simple,mycss.scss]
jupyter: shenfun
pandoc:
  to: revealjs
  output-file: introduction.html
  standalone: false
  wrap: none
  default-image-extension: png
  html-math-method:
    method: mathjax
    url: >-
      https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js
  slide-level: 2
metadata:
  width: 1200
  margin: 0.4
  topheight: 2mm
---

## A little bit about myself:

- PhD (2005) in turbulent combustion from Chalmers University of Technology, Sweden
- Post Doc (2006) at Sydney University
- Research scientist (2006-2012) at the Norwegian Defence Research Establishment
- Associate Professor at the University of Oslo (2012-2019)
- Full Professor at UiO since 2019

. . .

![](sunny.jpg){.absolute top=550 left=300 width="100"}
![](The_University_of_Oslo.jpg){.absolute top=650 left=280 width="150"}
[which today is sunny and nice 20 $^{o}$C]{.absolute top=800 left=100}

## Main interests

- Computational Fluid Dynamics
- Turbulence and turbulence modelling
- Scientific computing
- High-performance computing
- The spectral Galerkin method

## Principal developer of Shenfun

High performance computing platform for solving partial differential equations (PDEs) by the spectral Galerkin method


![](https://raw.githack.com/spectralDNS/spectralutilities/master/figures/strong_scaling_pencil_col.png){.absolute top=200 left=0 width="500" height="300"}

![](https://raw.githack.com/spectralDNS/spectralutilities/master/movies/Kuramato_movie_128.gif){.absolute top=520 left=750 width="400" height="400"}

![](https://raw.githack.com/spectralDNS/spectralutilities/master/movies/KHmovie_3.gif){.absolute top=600 left=0 width="400" height=300}

![](https://raw.githack.com/spectralDNS/spectralutilities/master/movies/isotropic300_12.gif){.absolute top=200 left=800 width="400" height="300"}

![](https://cdn.jsdelivr.net/gh/spectralDNS/spectralutilities@master/figures/moebius8_trans.png){.absolute top=300 left=550 width="200" height="200"}

![](https://raw.githack.com/spectralDNS/spectralutilities/master/figures/torus2.png){.absolute top=650 left=400 width="300" height="200"}

## Recent papers using Shenfun {.smaller}

- [<span style="color:green"> Solving Partial Differential Equations with Equivariant Extreme Learning Machines</span>](https://www.researchgate.net/profile/Sebastian-Peitz/publication/380897446_Solving_Partial_Differential_Equations_with_Equivariant_Extreme_Learning_Machines/links/66544d0fbc86444c7205cbdb/Solving-Partial-Differential-Equations-with-Equivariant-Extreme-Learning-Machines.pdf), H. Harder, J. Rabault, R. Vinuesa, M. Mortensen, S. Peitz. Submitted (2024)
- Vorticity Topology in Turbulent Micropolar Flows, **George Sofiadis**, **Ioannis J. Sarris**, M. Mortensen. In preparation (2024) 
- [A global spectral-Galerkin investigation of a Rayleigh–Taylor instability in plasma using an MHD–Boussinesq model](https://pubs.aip.org/aip/adv/article/13/10/105319/2917415)  A. Piterskaya, Wojciech J. Miloch, M. Mortensen, AIP Advances 13, 105319 (2023)
- [<span style="color:green">Effective control of two-dimensional Rayleigh–Bénard convection: Invariant multi-agent reinforcement learning is all you need</span>](https://pubs.aip.org/aip/pof/article/35/6/065146/2900730) C. Vignon, J. Rabault, J. Vasanth, F. Alcántara-Ávila, M. Mortensen, R. Vinuesa, Physics of Fluids 35, 065146 (2023)
- [A Generic and Strictly Banded Spectral Petrov–Galerkin Method for Differential Equations with Polynomial Coefficients](https://epubs.siam.org/doi/full/10.1137/22M1492842) M. Mortensen, SIAM J. on Scientific Computing, 45, 1, A123-A146, (2023)
- [<span style="color:green">Variance representations and convergence rates for data-driven approximations of Koopman operators</span>](https://arxiv.org/abs/2402.02494) F. M. Philipp, M. Schaller, S. Boshoff, S. Peitz, F. Nüske, K. Worthmann, submitted (2024)
- [<span style="color:green">Partial observations, coarse graining and equivariance in Koopman operator theory for large-scale dynamical systems</span>](https://arxiv.org/abs/2307.15325), S. Peitz, H. Harder, F. Nüske, F. Philipp, M. Schaller, K. Worthmann, submitted (2024)
- [<span style="color:green">Koopman-Based Surrogate Modelling of Turbulent Rayleigh-Bénard Convection</span>](https://arxiv.org/abs/2405.06425) T. Markmann, M. Straat, B. Hammer, submitted (2024)
- [Shenfun: High performance spectral Galerkin computing platform](https://joss.theoj.org/papers/10.21105/joss.01071.pdf), M. Mortensen, Journal of Open Source Software, 3(31), 1071 (2018)

<span style="color:green">Green papers deal with different aspects of machine learning, where Shenfun is used as PDE solver in the background</span>

## Outline of talk

- The spectral Galerkin method
- An introduction to Shenfun
- Some Shenfun examples

## The problem at hand

We will consider any **linear** equation of any order and dimension

$$
\begin{align}
u(x) &= f(x) \\
u''(x) + xu(x) &= f(x) \\
\nabla^2 u(x, y) + (1-x^2)u(x, y) &= f(x, y) \\
\Delta^2 u(x, y, z) &= f(x, y, z)
\end{align}
$$

or quite generally with an operator $\mathcal{L}$:

$$
\begin{equation}
\mathcal{L}(u) = f
\end{equation}
$$

The function $u(\boldsymbol{x})$ is the **solution**. And of course all differential equations require appropriate **boundary conditions**

$$
\mathcal{B}(u)=g
$$

We will only consider homogeneous boundary conditions, where $g=0$ even though Shenfun can handle any inhomogeneous boundary conditions.

## Global approximations

A **global** discretization method tries to approximate $u(x)$ using 

$$
u(x) \approx u_N(x) = \sum_{i=0}^N \hat{u}_i \psi_i(x), \quad x \in [a, b]
$$

where $\{\hat{u}_i\}_{i=0}^N$ are unknown coefficients (degrees of freedom).

The **global** functions $\psi_i(x)$ are **basisfunctions**. We say that 

$$\{\psi_i\}_{i=0}^N$$ 

is a **basis** and $\psi_i$ are also called **test** or **trial** functions. 

$$V_N = \text{span}\{\psi_j\}_{j=0}^N$$

represents a **functionspace**.

## Global vs local methods

Local methods use basis functions that are defined only locally. 

- Finite element methods
- Spectral element method
- Finite volume
- Finite difference

Low order, but high flexibility. At least for the first three.
Can easily handle complex geometries.

Low accuracy compared to global methods.

![](fe_mesh1D_phi_i_im1.png){.absolute left=100 width=800}

## What is the global Galerkin method? 

. . .

**A simple example**

Assume that $f(x) = x^2$ for $x \in [0, 1]$. Try to find the best possible approximation

$$u_N(x) = f(x)$$

when the basis is $\{1, x\}$ such that the functionspace $V_N=\text{span}\{1, x\}$ is the space of all linear functions.

. . .

&nbsp;

In other words, find the unknown $\{\hat{u}_0, \hat{u}_1\}$ such that

$$
u_N(x) = \hat{u}_0 \cdot 1 + \hat{u}_1 \cdot x
$$

is the best possible approximation to $x^2$.

. . .

&nbsp;

How is this possible? What options are there? What is **best**?

## What is the best approximation?

. . .

- Two-point Collocation?

. . .

Match endpoints $x_0=0$ and $x_1=1$. Set
$$u_N(x_i)=\hat{u}_0 + \hat{u}_1 x_i=f(x_i) \quad \text{for}\, i=0, 1$$

. . .

We get
$$
\begin{align}
\hat{u}_0 + \hat{u}_1 \cdot 0 &= 0^2 \\
\hat{u}_0 + \hat{u}_1 \cdot 1 &= 1^2
\end{align}
$$

Two equations for two unknowns. Solution: $\hat{u}_0=0, \hat{u}_1=1$

$$
u_N(x) = x
$$

## Two-point collocation

```{python}
#| echo: false
#| code-line-numbers: "3-5"
import numpy as np
import matplotlib.pyplot as plt
x = np.linspace(0, 1, 100)
plt.plot(x, x**2, 'r', x, x, 'b')
plt.legend(['Exact', 'Collocation'], fontsize=18)
```

. . .

Is this the best possible approximation? In what sense? How do we pick the collocation points $x_i$ in general?

## What is the best approximation?

- <span style="color:gray">Two-point Collocation?</span>
- The least squares method?

. . .

Define the error as 

$$
e(x) = f(x)-u_N(x)
$$

Define the $L^2$(a, b) inner product as 

$$
(g, h) = \int_{a}^b g \cdot h \, dx
$$

for some functions $g(x)$ and $h(x)$.

## The least squares method

Define a global error $E = (e, e) = |e|^2$. The least squares method requires 

$$
\frac{\partial E}{\partial \hat{u}_i} = 0, \quad i = 0, 1,
$$

which is two equations for our two unknowns.

. . .

&nbsp;

Insert for $e=f-u_N$ and use $\frac{\partial u_N}{\partial \hat{u}_i} = \psi_i$ to obtain after a lot of work:

$$
\sum_{j=0}^1(\psi_j, \psi_i) \hat{u}_j = (f, \psi_i), \quad i=0, 1.
$$

A linear system of equations to solve for vector $\boldsymbol{\hat{u}}=(\hat{u}_0, \hat{u}_1)$ with a mass matrix $a_{ij}=(\psi_j, \psi_i) \in \mathbb{R}^{2 \times 2}$. 

## Least square implementation {visibility="hidden"}

We can implement our testcase easily using Sympy. Assemble matrix $A=(a_{ij}) \in \mathbb{R}^{2 \times 2}$

```{python}
#|echo: true
import sympy as sp
from IPython.display import display
x = sp.symbols('x')
def inner(u, v, domain=(0, 1), x=x):
    return sp.integrate(u*v, (x, domain[0], domain[1]))

A = sp.Matrix(((inner(1, 1), inner(1, x)),
               (inner(x, 1), inner(x, x))))
display(A)
```

## Solve {visibility="hidden"}
Assemble $\boldsymbol{f} = (f, \psi_i)$ for $i=0, 1$
```{python}
#|echo: true
f = x**2
b = sp.Matrix(((inner(f, 1)), (inner(f, x))))
display(b)
```
Solve linear algebra system $A \boldsymbol{\hat{u}}=\boldsymbol{f}$ for $\boldsymbol{\hat{u}}$
```{python}
#|echo: true
u_hat = A.solve(b)
display(u_hat)
```
We get the solution $u_N$:
```{python}
#|echo: true
display(u_hat[0]+u_hat[1]*x)
```
## Least squares method

The solution becomes: $u_N(x) = -\frac{1}{6}+x$
```{python}
#| echo: false
#| code-line-numbers: "5"
xj = np.linspace(0, 1, 100)
plt.plot(xj, xj**2, 'r', xj, xj, 'b', xj, -1./6.+xj, 'g')
plt.legend(['Exact', 'Collocation', 'Least squares'], fontsize=18)
```
. . .

The least squares method becomes a bit messy for differential equations and is not much used for solving PDEs.


## What is the best approximation?

- <span style="color:gray">Two-point Collocation?</span>
- <span style="color:gray">The least squares method?</span>
- The Galerkin method?

. . .

The Galerkin method is similar to the least square method. Both are **variational** methods. However, the approach is much simpler. We simply require that the **error is $L^2$ orthogonal to the test functions** $\psi_i$:

. . .

&nbsp;    

For our simple test problem this means: Find $\hat{u}_0, \hat{u}_1$ such that

$$
(e, \psi_i) = 0, \quad \text{for}\quad i=0,1.
$$

Again two equations for two unknowns.

## Solve Galerkin

Insert for $e = f - u_N$ to get 

$$
(f - \sum_{j=0}^1 \hat{u}_j \psi_j, \psi_i) = 0, \quad i=0, 1.
$$

We get the same equation as with the least squares method

$$
\sum_{j=0}^1 (\psi_j, \psi_i) \hat{u}_j = (f, \psi_i), \quad i=0, 1.
$$

and obviously the same solution (but with less hard work!).

## The global Galerkin method in a nutshell

- Choose basis functions $\psi_i$ that span the entire domain and satisfy any (homogeneous) boundary conditions (for differential equations)

. . .

- Create a functionspace $V_N=\text{span}\{\psi_i\}_{i=0}^N$ that thus incorporates the boundary conditions

. . .

- Find $u_N \in V_N$. This implies that

$$
u_N(x) = \sum_{i=0}^N \hat{u}_i \psi_i(x)
$$

. . .

- Such that the error 

$$
e(x)=\mathcal{L}(u_N)-f
$$ 

is $L^2$-orthogonal to all $\psi_i$. 


## Galerkin

With the Galerkin method the problem 

$$
\mathcal{L}(u) = f
$$

is often formulated follows: Find $u_N \in V_N$ such that

$$
(\underbrace{\mathcal{L}(u_N)-f}_{e(x)}, v) = 0, \quad \forall v \in V_N
$$

where $u_N$ is called a **trial function** and $v$ a **test function**. For the Galerkin method test and trial spaces are **identical**.

. . .

This is also the same as saying: Find $u_N \in V_N$ such that

$$
(\mathcal{L}(u_N)-f, \psi_i) = 0, \quad \forall \, i=0, 1, \ldots, N.
$$

. . .

N+1 equations for N+1 unknowns $\{\hat{u}_i\}_{i=0}^N$. Remember that boundary conditions are included in $V_N$.

## What are the best basis functions?

. . .

- Sines and cosines (or periodic complex Fourier exponentials $e^{\hat{\imath} j\pi x}$)

For example $\psi_j = \sin((j+1)(x+1)\pi), x \in [-1,1]$

```{python}
M = 100
xj = np.linspace(-1, 1, M+1)
sines = np.sin(np.pi/2*(np.arange(6)[None, :]+1)*(xj[:, None]+1))
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))
ax1.plot(xj, sines[:, ::2])
ax2.plot(xj, sines[:, 1::2])
ax1.set_title('Even basis functions')
ax2.set_title('Odd basis functions')
ax1.legend([f"$\psi_{i}(x)$" for i in range(0, 6, 2)]);
ax2.legend([f"$\psi_{i}(x)$" for i in range(1, 6, 2)]);
```

With homogeneous Dirichlet boundary conditions built into 

$$V_N=\text{span}\{\sin((j+1)(x+1)\pi)\}_{j=0}^N$$

## What are the best basis functions?

. . .

- <span style="color:gray">sines and cosines (or periodic complex Fourier exponentials $e^{\hat{\imath}j\pi x}$)</span>
- Chebyshev polynomials $\psi_j = T_j(x)$
- Legendre polynomials $\psi_j = L_j(x)$
```{python}
M = 100
xj = np.linspace(-1, 1, M+1)
cheb = np.polynomial.chebyshev.chebvander(xj, 5)
leg = np.polynomial.legendre.legvander(xj, 5)
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))
ax1.plot(xj, cheb)
ax2.plot(xj, leg)
ax1.set_title('Chebyshev basis functions', fontsize=16)
ax2.set_title('Legendre basis functions', fontsize=16)
ax1.legend([f"$T_{i}(x)$" for i in range(0, 5)], loc='lower right')
ax2.legend([f"$L_{i}(x)$" for i in range(0, 5)])
```

Also odd/even functions for odd/even indices.

. . .

But no boundary conditions built in!

## Chebyshev/Legendre with Dirichlet 


- Chebyshev polynomials $\psi_j = T_j(x)-T_{j+2}(x)$
- Legendre polynomials $\psi_j = L_j(x)-L_{j+2}(x)$
```{python}
M = 100
xj = np.linspace(-1, 1, M+1)
cheb = np.polynomial.chebyshev.chebvander(xj, 5)
leg = np.polynomial.legendre.legvander(xj, 5)
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))
ax1.plot(xj, cheb[:, :-2]-cheb[:, 2:])
ax2.plot(xj, leg[:, :-2]-leg[:, 2:])
ax1.set_title('Chebyshev', fontsize=16)
ax2.set_title('Legendre', fontsize=16)
ax1.legend([f"$T_{i}(x)-T_{i+2}(x)$" for i in range(0, 5)], loc='lower right')
ax2.legend([f"$L_{i}(x)-L_{i+2}(x)$" for i in range(0, 5)])
```

- Still odd/even functions for odd/even indices.
- $V_N=\text{span}\{T_j-T_{j+2}\}_{j=0}^N$ has homogeneous Dirichlet boundary conditions built in.
- There are similar bases for different boundary conditions.

## How about multiple dimensions?

. . .

- Choose one basis for each direction and create tensor product basis functions on Cartesian product grids.

$$
u_N(x, y) = \sum_{i=0}^N \sum_{j=0}^N \hat{u}_{ij} \psi_i(x)\psi_j(y)
$$

- Tensor product functionspace with basis functions $\{\psi_i(x)\psi_j(y)\}_{i,j=0}^N$
$$
W = V_N \otimes V_N
$$

- Inner products are still taken over entire domain $\Omega=[a,b]\times [c, d]$

$$
(f, g) = \int_{a}^b \int_{c}^d f(x, y) g(x, y) dx dy
$$

## Channel flow

- Turbulent channel flow is an ideal case for the spectral Galerkin method.
- Cartesian grid $[-1, 1] \times [0, 2\pi] \times [0, 2\pi]$
- Chebyshev $\times$ Fourier $\times$ Fourier


![](https://rawcdn.githack.com/spectralDNS/spectralutilities/473129742f0b5f8d57e8c647809272c0ced99a45/movies/RB_200k_small.png)


## The spectral Galerkin method

### Advantages {.smaller}

- Makes use of oscillating basis functions with **extremely good approximation properties**. 
- Coefficient matrices are often **sparse**
- Coefficient matrices are **robust** (low condition numbers)

### However {.smaller}

:::: {.columns}

::: {.column width="60%"}
- No complex geometries, but curvilinear coordinates are ok.
- Nonlinear terms implemented explicitly (pseudospectral)
- Generally considered more difficult to implement since we solve equations in spectral space
:::

::: {.column width="40%"}
<img src="https://uio-my.sharepoint.com/:i:/r/personal/mikaem_uio_no/Documents/Ginzburg-Landau.png?csf=1&web=1&e=JhneJh" width=300>

:::

::::


## Shenfun

- Shenfun aims to **automate** the implementation of the spectral Galerkin method
- Uses a **high-level language**, where function spaces and equations are defined and combined 
- Uses MPI to run on multiple processors on supercomputers


<img src="https://rawcdn.githack.com/spectralDNS/spectralutilities/473129742f0b5f8d57e8c647809272c0ced99a45/movies/RB_200k_small.png" style="float:left" width="600">
<img src="https://rawcdn.githack.com/spectralDNS/spectralutilities/473129742f0b5f8d57e8c647809272c0ced99a45/movies/isotropic_cropped.gif" style="float:right" width="400"> 
<p style="clear: both;">
